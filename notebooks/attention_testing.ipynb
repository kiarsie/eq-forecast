{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45049749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: inline in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabriel\\documents\\development\\miniconda3\\envs\\attention\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62477b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\Gabriel\\Documents\\GitHub\\eq-forecast\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# CHECKING DIRECTORY\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23fb3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6ea66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3ce25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'latitude', 'longitude', 'depth', 'magnitude', 'Date_Time', 'origin_time']\n",
      "First rows:\n",
      "    id  latitude  longitude  depth  magnitude                 Date_Time  \\\n",
      "0   0       4.0      127.0    100        7.0 1909-04-25 14:36:00+00:00   \n",
      "1   1       4.5      126.5     33        7.5 1910-12-16 06:45:00+00:00   \n",
      "2   2       6.0      126.0    100        6.8 1911-03-06 09:30:00+00:00   \n",
      "3   3       9.0      126.0     33        7.7 1911-07-11 20:07:36+00:00   \n",
      "4   4       4.0      127.0     33        7.5 1912-08-17 11:11:48+00:00   \n",
      "\n",
      "     origin_time  \n",
      "0 -1915089840000  \n",
      "1 -1863278100000  \n",
      "2 -1856356200000  \n",
      "3 -1845345144000  \n",
      "4 -1810558092000  \n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing.load_catalog import load_catalog\n",
    "\n",
    "# Load DataFrame and CSEPCatalog object\n",
    "df, catalog = load_catalog(\"../data/eq_catalog.csv\")\n",
    "\n",
    "# Preview\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"First rows:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9bab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df[['origin_time', 'latitude', 'longitude', 'depth', 'magnitude']].copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e18d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 10   # Lookback window\n",
    "Ty = 1    # Predict 1 future step\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(Tx, len(scaled_features)):\n",
    "    X.append(scaled_features[i - Tx:i])\n",
    "    y.append(scaled_features[i, -1])  # magnitude\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(-1, Ty, 1)\n",
    "s = X.transpose(0, 2, 1)  # For spatial attention: (samples, features, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c4f8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "\n",
    "x_train, x_val, x_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n",
    "s_train, s_val, s_test = s[:train_size], s[train_size:train_size+val_size], s[train_size+val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27ea7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.attention import build_attention_model\n",
    "\n",
    "inp_var = 5\n",
    "h_s = 32\n",
    "dropout = 0.2\n",
    "con_dim = 4\n",
    "\n",
    "pred_model, prob_model = build_attention_model(Tx, Ty, inp_var, h_s, dropout, con_dim)\n",
    "pred_model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61d73242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0542 - val_loss: 0.0110\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0159 - val_loss: 0.0104\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.0190\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0089 - val_loss: 0.0162\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - val_loss: 0.0142\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - val_loss: 0.0150\n"
     ]
    }
   ],
   "source": [
    "s0_train = np.zeros((x_train.shape[0], h_s))\n",
    "c0_train = np.zeros((x_train.shape[0], h_s))\n",
    "yhat0_train = np.zeros((x_train.shape[0], 1))\n",
    "\n",
    "outputs_train = list(y_train.swapaxes(0, 1))  # List of Ty arrays\n",
    "\n",
    "history = pred_model.fit(\n",
    "    [x_train, s_train, s0_train, c0_train, yhat0_train],\n",
    "    outputs_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d25f7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "s0_test = np.zeros((x_test.shape[0], h_s))\n",
    "c0_test = np.zeros((x_test.shape[0], h_s))\n",
    "yhat0_test = np.zeros((x_test.shape[0], 1))\n",
    "\n",
    "predictions = pred_model.predict([x_test, s_test, s0_test, c0_test, yhat0_test])\n",
    "attn_outputs = prob_model.predict([x_test, s_test, s0_test, c0_test, yhat0_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8771c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ty = 1\n",
    "\n",
    "alphas = np.array([attn_outputs[i] for i in range(1, Ty * 3, 3)]).squeeze(-1).transpose(1, 0, 2)\n",
    "betas = np.array([attn_outputs[i] for i in range(2, Ty * 3, 3)]).squeeze(-1).transpose(1, 0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.stem(range(Tx), alphas[sample_idx, 0])\n",
    "plt.title(f'Temporal Attention - Sample {sample_idx}')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['origin_time', 'latitude', 'longitude', 'depth', 'magnitude']\n",
    "plt.bar(feature_names, betas[sample_idx, 0])\n",
    "plt.title(f'Spatial Attention - Sample {sample_idx}')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arr = np.array(predictions).squeeze().reshape(-1, Ty)\n",
    "true_arr = y_test.reshape(-1, Ty)\n",
    "\n",
    "# Inverse transform\n",
    "padded_pred = np.hstack([np.zeros((pred_arr.shape[0], 4)), pred_arr])\n",
    "padded_true = np.hstack([np.zeros((true_arr.shape[0], 4)), true_arr])\n",
    "inv_pred = scaler.inverse_transform(padded_pred)[:, -1]\n",
    "inv_true = scaler.inverse_transform(padded_true)[:, -1]\n",
    "\n",
    "# Plot\n",
    "plt.plot(inv_true[:100], label='Actual')\n",
    "plt.plot(inv_pred[:100], label='Predicted')\n",
    "plt.title('Predicted vs Actual Magnitude')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
