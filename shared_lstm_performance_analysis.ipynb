{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shared LSTM Performance Analysis Notebook\n",
        "\n",
        "This notebook provides comprehensive analysis of the Shared LSTM earthquake forecasting model performance, including:\n",
        "- Training history visualization\n",
        "- Accuracy metrics per spatial bin\n",
        "- Zero frequency bin analysis by year\n",
        "- Model predictions vs actual values\n",
        "- Spatial performance distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.append(str(Path.cwd() / \"src\"))\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "from src.models.shared_lstm_model import SharedLSTMModel, WeightedEarthquakeLoss\n",
        "from src.models.shared_lstm_trainer import SharedLSTMTrainer\n",
        "from src.models.enhanced_shared_processor import EnhancedSharedDataset\n",
        "from src.preprocessing.earthquake_processor import EarthquakeProcessor\n",
        "from src.binning.quadtree import extract_leaf_bounds, count_events_in_bin\n",
        "\n",
        "print(\"All modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Trained Model and Data\n",
        "\n",
        "First, let's load the trained model and prepare the data for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "MODEL_PATH = \"models/shared_lstm_best.pth\"  # Update with your model path\n",
        "DATA_PATH = \"data/processed_earthquakes.csv\"  # Update with your data path\n",
        "CONFIG_PATH = \"config_example.json\"  # Update with your config path\n",
        "\n",
        "# Load configuration\n",
        "if os.path.exists(CONFIG_PATH):\n",
        "    with open(CONFIG_PATH, 'r') as f:\n",
        "        config = json.load(f)\n",
        "    print(\"Configuration loaded:\")\n",
        "    print(json.dumps(config, indent=2))\n",
        "else:\n",
        "    print(f\"Config file not found at {CONFIG_PATH}\")\n",
        "    config = {}\n",
        "\n",
        "# Check if model exists\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    print(f\"\\nModel found at: {MODEL_PATH}\")\n",
        "else:\n",
        "    print(f\"\\nModel not found at: {MODEL_PATH}\")\n",
        "    print(\"Please update MODEL_PATH with the correct path to your trained model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed earthquake data\n",
        "if os.path.exists(DATA_PATH):\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"Data loaded: {len(df)} records\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "    \n",
        "    # Display sample data\n",
        "    print(\"\\nSample data:\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(f\"Data file not found at {DATA_PATH}\")\n",
        "    print(\"Please update DATA_PATH with the correct path to your processed data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Performance Analysis\n",
        "\n",
        "Let's analyze the model's performance across different metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_evaluate_model(model_path, test_loader, device='auto'):\n",
        "    \"\"\"Load trained model and evaluate on test data.\"\"\"\n",
        "    if device == 'auto':\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Load model checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Extract model architecture info\n",
        "    input_size = checkpoint.get('input_size', 64)\n",
        "    hidden_size = checkpoint.get('hidden_size', 32)\n",
        "    num_layers = checkpoint.get('num_layers', 2)\n",
        "    \n",
        "    # Create model instance\n",
        "    model = SharedLSTMModel(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers\n",
        "    )\n",
        "    \n",
        "    # Load state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Model loaded successfully on {device}\")\n",
        "    print(f\"Architecture: {input_size} â†’ {hidden_size} (layers: {num_layers})\")\n",
        "    \n",
        "    return model, checkpoint\n",
        "\n",
        "# Note: This function requires a test_loader to be available\n",
        "# You'll need to create the data loaders based on your data structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training History Visualization\n",
        "\n",
        "If you have training history available, let's visualize the training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(checkpoint):\n",
        "    \"\"\"Plot training history from checkpoint.\"\"\"\n",
        "    if 'training_history' not in checkpoint:\n",
        "        print(\"No training history found in checkpoint\")\n",
        "        return\n",
        "    \n",
        "    history = checkpoint['training_history']\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    \n",
        "    # Total loss\n",
        "    if 'train_losses' in history and 'val_losses' in history:\n",
        "        axes[0, 0].plot(history['train_losses'], label='Train', linewidth=2)\n",
        "        axes[0, 0].plot(history['val_losses'], label='Validation', linewidth=2)\n",
        "        axes[0, 0].set_title('Total Loss', fontsize=14, fontweight='bold')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Magnitude loss\n",
        "    if 'train_magnitude_losses' in history and 'val_magnitude_losses' in history:\n",
        "        axes[0, 1].plot(history['train_magnitude_losses'], label='Train', linewidth=2)\n",
        "        axes[0, 1].plot(history['val_magnitude_losses'], label='Validation', linewidth=2)\n",
        "        axes[0, 1].set_title('Magnitude Loss (MSE)', fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Loss')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Frequency loss\n",
        "    if 'train_frequency_losses' in history and 'val_frequency_losses' in history:\n",
        "        axes[0, 2].plot(history['train_frequency_losses'], label='Train', linewidth=2)\n",
        "        axes[0, 2].plot(history['val_frequency_losses'], label='Validation', linewidth=2)\n",
        "        axes[0, 2].set_title('Frequency Loss (Poisson NLL)', fontsize=14, fontweight='bold')\n",
        "        axes[0, 2].set_xlabel('Epoch')\n",
        "        axes[0, 2].set_ylabel('Loss')\n",
        "        axes[0, 2].legend()\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Magnitude MAE\n",
        "    if 'train_magnitude_mae' in history and 'val_magnitude_mae' in history:\n",
        "        axes[1, 0].plot(history['train_magnitude_mae'], label='Train', linewidth=2)\n",
        "        axes[1, 0].plot(history['val_magnitude_mae'], label='Validation', linewidth=2)\n",
        "        axes[1, 0].set_title('Magnitude MAE', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('MAE')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Frequency MAE\n",
        "    if 'train_frequency_mae' in history and 'val_frequency_mae' in history:\n",
        "        axes[1, 1].plot(history['train_frequency_mae'], label='Train', linewidth=2)\n",
        "        axes[1, 1].plot(history['val_frequency_mae'], label='Validation', linewidth=2)\n",
        "        axes[1, 1].set_title('Frequency MAE', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "        axes[1, 1].set_ylabel('MAE')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Best validation loss\n",
        "    best_val_loss = checkpoint.get('best_val_loss', None)\n",
        "    if best_val_loss:\n",
        "        axes[1, 2].axhline(y=best_val_loss, color='red', linestyle='--', \n",
        "                           label=f'Best Val Loss: {best_val_loss:.4f}', linewidth=2)\n",
        "        axes[1, 2].set_title('Best Validation Loss', fontsize=14, fontweight='bold')\n",
        "        axes[1, 2].set_xlabel('Epoch')\n",
        "        axes[1, 2].set_ylabel('Loss')\n",
        "        axes[1, 2].legend()\n",
        "        axes[1, 2].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (uncomment when you have a checkpoint):\n",
        "# plot_training_history(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Bin-wise Performance Analysis\n",
        "\n",
        "This section analyzes the model's performance for each spatial bin, including accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_bin_performance(df, model, bin_column='bin_id'):\n",
        "    \"\"\"Analyze model performance for each spatial bin.\"\"\"\n",
        "    if bin_column not in df.columns:\n",
        "        print(f\"Column '{bin_column}' not found in data. Available columns: {list(df.columns)}\")\n",
        "        return None\n",
        "    \n",
        "    # Group by bin and calculate metrics\n",
        "    bin_metrics = []\n",
        "    \n",
        "    for bin_id in df[bin_column].unique():\n",
        "        bin_data = df[df[bin_column] == bin_id]\n",
        "        \n",
        "        if len(bin_data) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Calculate basic statistics\n",
        "        metrics = {\n",
        "            'bin_id': bin_id,\n",
        "            'total_events': len(bin_data),\n",
        "            'mean_magnitude': bin_data['magnitude'].mean() if 'magnitude' in bin_data.columns else np.nan,\n",
        "            'std_magnitude': bin_data['magnitude'].std() if 'magnitude' in bin_data.columns else np.nan,\n",
        "            'min_magnitude': bin_data['magnitude'].min() if 'magnitude' in bin_data.columns else np.nan,\n",
        "            'max_magnitude': bin_data['magnitude'].max() if 'magnitude' in bin_data.columns else np.nan,\n",
        "            'mean_frequency': bin_data['frequency'].mean() if 'frequency' in bin_data.columns else np.nan,\n",
        "            'zero_frequency_count': len(bin_data[bin_data['frequency'] == 0]) if 'frequency' in bin_data.columns else np.nan,\n",
        "            'zero_frequency_ratio': len(bin_data[bin_data['frequency'] == 0]) / len(bin_data) if 'frequency' in bin_data.columns else np.nan\n",
        "        }\n",
        "        \n",
        "        bin_metrics.append(metrics)\n",
        "    \n",
        "    return pd.DataFrame(bin_metrics)\n",
        "\n",
        "# Analyze bin performance\n",
        "if 'df' in locals():\n",
        "    bin_performance = analyze_bin_performance(df, None, 'bin_id')\n",
        "    if bin_performance is not None:\n",
        "        print(\"Bin Performance Summary:\")\n",
        "        display(bin_performance.head(10))\n",
        "        \n",
        "        # Summary statistics\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(f\"Total bins: {len(bin_performance)}\")\n",
        "        print(f\"Bins with zero frequency: {len(bin_performance[bin_performance['zero_frequency_ratio'] > 0])}\")\n",
        "        print(f\"Average events per bin: {bin_performance['total_events'].mean():.2f}\")\n",
        "else:\n",
        "    print(\"Data not loaded yet. Please run the data loading cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Zero Frequency Bin Analysis by Year\n",
        "\n",
        "This section identifies bins with zero frequency and analyzes their temporal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_zero_frequency_bins(df, date_column='date', bin_column='bin_id', frequency_column='frequency'):\n",
        "    \"\"\"Analyze bins with zero frequency and their temporal distribution.\"\"\"\n",
        "    required_columns = [date_column, bin_column, frequency_column]\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Missing columns: {missing_columns}\")\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "        return None\n",
        "    \n",
        "    # Convert date column to datetime if needed\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df[date_column]):\n",
        "        df[date_column] = pd.to_datetime(df[date_column])\n",
        "    \n",
        "    # Extract year\n",
        "    df['year'] = df[date_column].dt.year\n",
        "    \n",
        "    # Find zero frequency events\n",
        "    zero_freq_data = df[df[frequency_column] == 0].copy()\n",
        "    \n",
        "    if len(zero_freq_data) == 0:\n",
        "        print(\"No zero frequency events found.\")\n",
        "        return None\n",
        "    \n",
        "    # Group by year and bin\n",
        "    yearly_zero_freq = zero_freq_data.groupby(['year', bin_column]).size().reset_index(name='zero_freq_count')\n",
        "    \n",
        "    # Group by year only\n",
        "    yearly_summary = yearly_zero_freq.groupby('year').agg({\n",
        "        'zero_freq_count': 'sum',\n",
        "        bin_column: 'nunique'\n",
        "    }).rename(columns={bin_column: 'unique_bins_with_zero_freq'})\n",
        "    \n",
        "    return yearly_zero_freq, yearly_summary\n",
        "\n",
        "# Analyze zero frequency bins\n",
        "if 'df' in locals():\n",
        "    zero_freq_analysis = analyze_zero_frequency_bins(df)\n",
        "    \n",
        "    if zero_freq_analysis is not None:\n",
        "        yearly_zero_freq, yearly_summary = zero_freq_analysis\n",
        "        \n",
        "        print(\"Zero Frequency Analysis by Year:\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Display yearly summary\n",
        "        print(\"\\nYearly Summary:\")\n",
        "        display(yearly_summary)\n",
        "        \n",
        "        # Display detailed breakdown\n",
        "        print(\"\\nDetailed Breakdown by Year and Bin:\")\n",
        "        display(yearly_zero_freq.head(20))\n",
        "        \n",
        "        # Plot zero frequency trends\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Plot 1: Total zero frequency events per year\n",
        "        ax1.plot(yearly_summary.index, yearly_summary['zero_freq_count'], \n",
        "                marker='o', linewidth=2, markersize=8)\n",
        "        ax1.set_title('Zero Frequency Events per Year', fontsize=14, fontweight='bold')\n",
        "        ax1.set_xlabel('Year')\n",
        "        ax1.set_ylabel('Count of Zero Frequency Events')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot 2: Unique bins with zero frequency per year\n",
        "        ax2.plot(yearly_summary.index, yearly_summary['unique_bins_with_zero_freq'], \n",
        "                marker='s', linewidth=2, markersize=8, color='orange')\n",
        "        ax2.set_title('Unique Bins with Zero Frequency per Year', fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Year')\n",
        "        ax2.set_ylabel('Number of Unique Bins')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Data not loaded yet. Please run the data loading cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Accuracy Metrics per Bin\n",
        "\n",
        "This section calculates and visualizes accuracy metrics for each spatial bin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_bin_accuracy_metrics(df, predictions_df, bin_column='bin_id'):\n",
        "    \"\"\"Calculate accuracy metrics for each bin using predictions vs actual values.\"\"\"\n",
        "    # This function requires predictions from the model\n",
        "    # For now, we'll create a placeholder structure\n",
        "    \n",
        "    print(\"Note: This function requires model predictions to calculate accuracy metrics.\")\n",
        "    print(\"You'll need to run the model on your test data to get predictions.\")\n",
        "    \n",
        "    # Placeholder for accuracy metrics structure\n",
        "    accuracy_metrics = {\n",
        "        'magnitude_mae': 'Mean Absolute Error for magnitude predictions',\n",
        "        'magnitude_rmse': 'Root Mean Square Error for magnitude predictions',\n",
        "        'magnitude_correlation': 'Correlation between predicted and actual magnitudes',\n",
        "        'frequency_mae': 'Mean Absolute Error for frequency predictions',\n",
        "        'frequency_rmse': 'Root Mean Square Error for frequency predictions',\n",
        "        'frequency_correlation': 'Correlation between predicted and actual frequencies',\n",
        "        'overall_accuracy': 'Combined accuracy score'\n",
        "    }\n",
        "    \n",
        "    return accuracy_metrics\n",
        "\n",
        "def plot_bin_accuracy_heatmap(accuracy_df, metric='magnitude_mae'):\n",
        "    \"\"\"Plot heatmap of accuracy metrics across bins.\"\"\"\n",
        "    if accuracy_df is None or len(accuracy_df) == 0:\n",
        "        print(\"No accuracy data available for plotting.\")\n",
        "        return\n",
        "    \n",
        "    # Create a sample heatmap (replace with actual data when available)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Sample data for demonstration\n",
        "    sample_bins = np.arange(20)\n",
        "    sample_metrics = np.random.rand(20)  # Replace with actual metrics\n",
        "    \n",
        "    plt.bar(sample_bins, sample_metrics, alpha=0.7, color='skyblue')\n",
        "    plt.title(f'Sample {metric.replace(\"_\", \" \").title()} Across Bins', \n",
        "              fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Bin ID')\n",
        "    plt.ylabel(metric.replace('_', ' ').title())\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Accuracy analysis functions defined. Run with actual predictions when available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Spatial Distribution Analysis\n",
        "\n",
        "Analyze the spatial distribution of model performance across different regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_spatial_distribution(df, lat_column='latitude', lon_column='longitude', bin_column='bin_id'):\n",
        "    \"\"\"Analyze spatial distribution of events and bins.\"\"\"\n",
        "    required_columns = [lat_column, lon_column, bin_column]\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Missing columns: {missing_columns}\")\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "        return None\n",
        "    \n",
        "    # Create spatial analysis plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Plot 1: Event density\n",
        "    axes[0, 0].scatter(df[lon_column], df[lat_column], \n",
        "                       c=df['magnitude'] if 'magnitude' in df.columns else np.random.rand(len(df)),\n",
        "                       alpha=0.6, s=20, cmap='viridis')\n",
        "    axes[0, 0].set_title('Earthquake Event Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Longitude')\n",
        "    axes[0, 0].set_ylabel('Latitude')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Bin distribution\n",
        "    if bin_column in df.columns:\n",
        "        bin_centers = df.groupby(bin_column).agg({\n",
        "            lon_column: 'mean',\n",
        "            lat_column: 'mean',\n",
        "            'magnitude': 'count' if 'magnitude' in df.columns else 'size'\n",
        "        }).reset_index()\n",
        "        \n",
        "        scatter = axes[0, 1].scatter(bin_centers[lon_column], bin_centers[lat_column], \n",
        "                                     c=bin_centers.iloc[:, -1], s=50, alpha=0.7, cmap='plasma')\n",
        "        axes[0, 1].set_title('Bin Distribution (Size = Event Count)', fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Longitude')\n",
        "        axes[0, 1].set_ylabel('Latitude')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter, ax=axes[0, 1])\n",
        "    \n",
        "    # Plot 3: Magnitude distribution\n",
        "    if 'magnitude' in df.columns:\n",
        "        axes[1, 0].hist(df['magnitude'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        axes[1, 0].set_title('Magnitude Distribution', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Magnitude')\n",
        "        axes[1, 0].set_ylabel('Frequency')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Frequency distribution\n",
        "    if 'frequency' in df.columns:\n",
        "        axes[1, 1].hist(df['frequency'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "        axes[1, 1].set_title('Frequency Distribution', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Frequency')\n",
        "        axes[1, 1].set_ylabel('Count')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Analyze spatial distribution\n",
        "if 'df' in locals():\n",
        "    analyze_spatial_distribution(df)\n",
        "else:\n",
        "    print(\"Data not loaded yet. Please run the data loading cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Predictions Analysis\n",
        "\n",
        "This section will analyze the model's predictions when available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_model_predictions(actual_values, predicted_values, metadata=None):\n",
        "    \"\"\"Analyze model predictions vs actual values.\"\"\"\n",
        "    if actual_values is None or predicted_values is None:\n",
        "        print(\"No prediction data available for analysis.\")\n",
        "        print(\"Please run the model on your test data first.\")\n",
        "        return None\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mae = np.mean(np.abs(predicted_values - actual_values))\n",
        "    rmse = np.sqrt(np.mean((predicted_values - actual_values) ** 2))\n",
        "    correlation = np.corrcoef(predicted_values, actual_values)[0, 1]\n",
        "    \n",
        "    # Create analysis plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Plot 1: Scatter plot of predictions vs actual\n",
        "    axes[0, 0].scatter(actual_values, predicted_values, alpha=0.6)\n",
        "    axes[0, 0].plot([actual_values.min(), actual_values.max()], \n",
        "                     [actual_values.min(), actual_values.max()], 'r--', linewidth=2)\n",
        "    axes[0, 0].set_title('Predictions vs Actual Values', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Actual Values')\n",
        "    axes[0, 0].set_ylabel('Predicted Values')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Residuals\n",
        "    residuals = predicted_values - actual_values\n",
        "    axes[0, 1].scatter(actual_values, residuals, alpha=0.6)\n",
        "    axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "    axes[0, 1].set_title('Residuals vs Actual Values', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Actual Values')\n",
        "    axes[0, 1].set_ylabel('Residuals')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Residuals distribution\n",
        "    axes[1, 0].hist(residuals, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "    axes[1, 0].set_title('Residuals Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Residuals')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Metrics summary\n",
        "    axes[1, 1].text(0.1, 0.8, f'MAE: {mae:.4f}', fontsize=12, transform=axes[1, 1].transAxes)\n",
        "    axes[1, 1].text(0.1, 0.7, f'RMSE: {rmse:.4f}', fontsize=12, transform=axes[1, 1].transAxes)\n",
        "    axes[1, 1].text(0.1, 0.6, f'Correlation: {correlation:.4f}', fontsize=12, transform=axes[1, 1].transAxes)\n",
        "    axes[1, 1].set_title('Performance Metrics', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'mae': mae,\n",
        "        'rmse': rmse,\n",
        "        'correlation': correlation\n",
        "    }\n",
        "\n",
        "print(\"Model predictions analysis function defined. Run with actual predictions when available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Recommendations\n",
        "\n",
        "This section provides a summary of the analysis and recommendations for model improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_performance_summary(df, bin_performance=None, zero_freq_analysis=None):\n",
        "    \"\"\"Generate a comprehensive performance summary.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SHARED LSTM PERFORMANCE ANALYSIS SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if df is not None:\n",
        "        print(f\"\\nðŸ“Š DATA OVERVIEW:\")\n",
        "        print(f\"   â€¢ Total records: {len(df):,}\")\n",
        "        print(f\"   â€¢ Date range: {df['date'].min()} to {df['date'].max()}\" if 'date' in df.columns else \"   â€¢ Date column not found\")\n",
        "        print(f\"   â€¢ Columns: {len(df.columns)}\")\n",
        "        \n",
        "        if 'magnitude' in df.columns:\n",
        "            print(f\"   â€¢ Magnitude range: {df['magnitude'].min():.2f} to {df['magnitude'].max():.2f}\")\n",
        "        \n",
        "        if 'frequency' in df.columns:\n",
        "            print(f\"   â€¢ Frequency range: {df['frequency'].min():.2f} to {df['frequency'].max():.2f}\")\n",
        "    \n",
        "    if bin_performance is not None:\n",
        "        print(f\"\\nðŸ—ºï¸  SPATIAL BIN ANALYSIS:\")\n",
        "        print(f\"   â€¢ Total bins: {len(bin_performance):,}\")\n",
        "        print(f\"   â€¢ Average events per bin: {bin_performance['total_events'].mean():.2f}\")\n",
        "        print(f\"   â€¢ Bins with zero frequency: {len(bin_performance[bin_performance['zero_frequency_ratio'] > 0]):,}\")\n",
        "    \n",
        "    if zero_freq_analysis is not None:\n",
        "        yearly_zero_freq, yearly_summary = zero_freq_analysis\n",
        "        print(f\"\\nðŸ” ZERO FREQUENCY ANALYSIS:\")\n",
        "        print(f\"   â€¢ Total zero frequency events: {yearly_zero_freq['zero_freq_count'].sum():,}\")\n",
        "        print(f\"   â€¢ Years with zero frequency: {len(yearly_summary):,}\")\n",
        "        if len(yearly_summary) > 0:\n",
        "            max_zero_year = yearly_summary['zero_freq_count'].idxmax()\n",
        "            max_zero_count = yearly_summary['zero_freq_count'].max()\n",
        "            print(f\"   â€¢ Year with most zero frequency: {max_zero_year} ({max_zero_count:,} events)\")\n",
        "    \n",
        "    print(f\"\\nðŸ“ˆ RECOMMENDATIONS:\")\n",
        "    print(f\"   1. Run the model on test data to get actual predictions\")\n",
        "    print(f\"   2. Calculate accuracy metrics per bin using predictions vs actual values\")\n",
        "    print(f\"   3. Analyze spatial patterns in model performance\")\n",
        "    print(f\"   4. Identify bins with poor performance for targeted improvement\")\n",
        "    print(f\"   5. Consider temporal patterns in zero frequency bins\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Generate summary\n",
        "if 'df' in locals():\n",
        "    generate_performance_summary(df, \n",
        "                                bin_performance if 'bin_performance' in locals() else None,\n",
        "                                zero_freq_analysis if 'zero_freq_analysis' in locals() else None)\n",
        "else:\n",
        "    print(\"Data not loaded yet. Please run the data loading cell first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Next Steps\n",
        "\n",
        "To complete the performance analysis, you'll need to:\n",
        "\n",
        "1. **Load your trained model** - Update the `MODEL_PATH` variable with the correct path\n",
        "2. **Prepare test data** - Ensure you have a test dataset with the same format as training data\n",
        "3. **Generate predictions** - Run the model on test data to get predictions\n",
        "4. **Calculate accuracy metrics** - Use the prediction functions to analyze performance\n",
        "5. **Customize visualizations** - Modify plots based on your specific needs\n",
        "\n",
        "The notebook provides a comprehensive framework for analyzing:\n",
        "- Training history and convergence\n",
        "- Spatial bin performance\n",
        "- Zero frequency patterns by year\n",
        "- Model prediction accuracy\n",
        "- Spatial distribution of performance\n",
        "\n",
        "Run each section sequentially to build a complete understanding of your model's performance!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
